---
title: "Proxlog testing Jan 26 "
output:
  pdf_document: default
  html_notebook: default
---
TESTS: 
Does downloading more often cause more data loss? (downloading to base station every time 15 reads are logged, vs every time 750 reads are logged) 

       Compare baseline and high download rate to see if high download rate results in higher rates of data loss
- % lost in 5 minutes  (over whole test) ( per tag, per dyad)
- % lost every minute? 

Compare baseline and lower sampling rate, and even lower sampling rate. Does a higher sampling rate cause more data loss? 
- compare each tag and each dyad
- convert to % loss --> reads observed/ reads expected *100


Battery life: extract # of reads over each .5 hour for each tag, see if it declines over time. 
histogram? time = hr? Summarize by time bins? 

Tag number: 
- Average data loss/ tag in 5 vs 10 treatments compare each tag and each dyad
- convert to % loss --> reads observed/ reads expected *100


	tag positions
	5N (towards recording booths)
	3W (towards exit)
	4E (towards cages)
	2S (towards monitor)
	1C
	
	5 minutes each


	((baseline))
	11:55:00-12:00:00  
	5 tags
	1 meter grid
	2 second sampling
	download at 750 reads
	
	((previous high downloading rate, possibly higher than before)
	12:01:00 - 12:06:00
	5 tags
	1 meter grid
	2 second sampling 
	download at 15 reads ( was maybe 2 during last tests)
	((changed over at ~12:00, waited to start bc maybe a backload of downloading)) 
	
	
	((lower sampling rate))
	12:08:00 - 12:13:00
	5 tags
	1 meter grid
	10 second sampling
	download at 750 reads
	
	((even lower sampling rate))
	12:15-12:20
	5 tags
	1 meter grid
	20 second sampling
	download at 750 reads
	
	(connected blutooth hotspot at mid 12:18-12:19, in case that had an effect) 
	-----
	((battery life)) 
	12:28
	5 tags, run all night 
	5 tags
	1 meter grid
	20 second sampling
	download at 750 reads
	
	@12:28: 
	1=83%
	2=92%
	3=92%
	4=91%
	5=78%
	
27/01/24
Tag number test (test 10 vs 5 tags to see if there is more data loss with 10 )
	00:13- 00:18
	10 tags
	In circle 
	5 second sampling 
	Download at 750 reads 
	
	00:20- 00:25
	5 tags 2,4,6,9,11  (alternate tags hidden: not scanning) 
	5 sec scanning
	Download at 750 reads 
	
	00:26- 00:31
	10 tags
	In circle 
	5 second sampling 
	Download at 750 reads
	
	0:33-0:38
	(Other 5 tags) 
	5 tags 1,3,5,7,10 (alternate tags hidden: not scanning) 
	5 sec scanning
	Download at 750 reads

	


#make test table with all dyads
#OR A TEST TABLE with just all tests
# add test info
# combine with tag- data


```{r, include = FALSE}

library(readr)
library(lubridate)
library(tibbletime)
library(tidyverse)
#library(cut.POSIXt)
```

--> Data wrangling: import data
```{r import data, include = FALSE}

# test_table defines the times when each test was conducted

# Use this code if pulling test_table from github (double check github sometimes pulls csvs in weird) 
 test_table <- read_csv("https://raw.githubusercontent.com/maydixon/proximity-sensors/real/test_table_Jan26.csv") 


# import proxlog data- take all the files in a folder and pull them into the same dataframe
# (for some obnoxious reason, L3 and L4 read in with col names automatically with read_CSV, and the others don't, so I used read.csv)
PR_DATA <- list.files(path = "proxlog_Jan26_test/",  # Identify all CSV files with L in the name
                       pattern = "L", full.names = TRUE) %>% #
  lapply(read.csv, col.names = c("RX_Node","TX_Node","Date_Time", "RSSI")) %>%                              # Store all files in list
  bind_rows         %>%                     # Combine data sets into one data set 
  mutate(tag = "proxlog") #add proxlog to all rows


### extra data from last test
PR_DATA_2 <- list.files(path = "Proxlogs_numtest/",  # Identify all CSV files with L in the name
                       pattern = "L", full.names = TRUE) %>% #
  lapply(read.csv, col.names = c("RX_Node","TX_Node","Date_Time", "RSSI")) %>%                              # Store all files in list
  bind_rows         %>%                     # Combine data sets into one data set 
  mutate(tag = "proxlog") #add proxlog to all rows

PR_DATA <- bind_rows(PR_DATA, PR_DATA_2)
## Tags 7, 10 and 11 originally have very much the wrong (default) times, but they do update before the tests. 

```

--> Data wrangling: fix and standardize Dulog and data_table, and proxlog date/times
```{r, include = FALSE}

# put date time in one column for reference table
test_table <- test_table %>%
      mutate(start_time = make_datetime(year = start_year, month = start_month, day = start_day, hour = start_hour, min =  start_minute, sec = start_second), 
             end_time = make_datetime(year = end_year, month = end_month, day = end_day, hour = end_hour, min =  end_minute, sec = end_second))


#Force into same timezone
test_table$start_time <-  force_tz(test_table$start_time, tzone = "America/New_York")
test_table$end_time <-  force_tz(test_table$end_time, tzone = "America/New_York")


#Make test_table for the test of whether more tags causes more data loss (all tags in 20cm circle, either 5 or 10 tags activated)
#entering the text_table directly here, to take advantage of complete() for making all possible dyads


#X = length of initial dataset, will all column values, pre using complete to make all possible combinations
X=10 #length of longest variable (tag_A and B here)
ntags_test_table <- tibble(
  tag = c(rep("proxlog", length.out = X)),
  test = c(rep(c("20cmcircle_10p_5s_750d_1","20cmcircle_5p_5s_750d_1", "20cmcircle_10p_5s_750d_2", "20cmcircle_5p_5s_750d_2"), length.out = X)),
    tag_A = c(1:7,9:11), 
  tag_B = c(1:7,9:11),
  start_time = as.POSIXct(c(rep(c("2024-01-27 00:13:00", "2024-01-27 00:20:00", "2024-01-27 00:26:00", "2024-01-27 00:33:00"), length.out = X))),
  end_time = as.POSIXct(c(rep(c("2024-01-27 00:18:00", "2024-01-27 00:25:00", "2024-01-27 00:31:00", "2024-01-27 00:38:00"), length.out = X))),
  N_tags = c(rep(c(10,5,10,5), length.out = X)),
  sample_rate = c(rep(5, length.out=X)),
  download_rate = c(rep(750, length.out=X))
) %>%
      complete(test, tag_A, tag_B) %>% #make all possible dyad combinations
      arrange(test,start_time) %>% #make it so filled values for each test come first to fill in missing values
      fill(c(tag, start_time, end_time, N_tags, sample_rate, download_rate), .direction = "down")  #fill in NAs
ntags_test_table 
      
#bind to test table 
test_table <- bind_rows(test_table, ntags_test_table)
```





```{r}


# correct date and time for PR_DATA

# PR_DATA, convert character to POSIX (OG timezone is a default GMT )
PR_DATA$Date_Time <-  as.POSIXlt(PR_DATA$Date_Time, format ="%d/%m/%Y %H:%M:%S", tz= "Etc/GMT" )

#change to real time zone, same format as other dataset
PR_DATA$Date_Time<- with_tz(PR_DATA$Date_Time, tzone = "America/New_York")
head(PR_DATA$Date_Time)
head(PR_DATA)



Tag_Data <- PR_DATA

#remove duplicate rows
Tag_Data <-Tag_Data %>%
  distinct(.keep_all = TRUE)


#rename tagA to RX_Node, and rename cardinal positions
# Make tag names indicate tag type (d or p), then unique ID e.g. "69"
test_table <- test_table %>%
      rename(RX_Node = tag_A,
             TX_Node = tag_B, 
             RX_Position = TagA_position, 
             TX_Position = Tag_B_position) %>%
      mutate_at( c("RX_Node", "TX_Node"), funs(ifelse(tag=="dulog", paste("d", ., sep=""), paste("p", ., sep=""))))

#delete
# test_table <- test_table %>%
#       mutate(RX_Node = paste(TagA_position, tag_A,  sep = ""), 
#              TX_Node = paste(Tag_B_position, tag_B, sep = "")) %>%
#       mutate_at( c("RX_Node", "TX_Node"), funs(ifelse(tag=="dulog", paste("d", ., sep=""), paste("p", ., sep=""))))
# 

# don't do this
#add cardinal position (N, S E W, C) to each tag type and tag brand
# really only for the grid tests
#make new columns to indicate locations of tags
Tag_Data <- Tag_Data %>%
      mutate_at(vars("RX_Node","TX_Node"), ~ as.character(.)) %>% 
      mutate(RX_Position = RX_Node, 
             TX_Position = TX_Node) %>% #make new variables for positions
      
      mutate_at(vars("RX_Position","TX_Position"), ~ case_when( . == "1" ~ paste("C"), # add position to all tags
                                                       . == "2" ~ paste("S"),
                                                       . == "3" ~ paste("W"),
                                                       . == "4" ~ paste("E"),
                                                       . == "5" ~ paste("N"),
                                                      TRUE ~ . #keep any original values that were not changed
                                                      )
              ) %>%
       mutate_at( vars("RX_Node", "TX_Node"), ~ ifelse(tag=="dulog", paste("d", ., sep=""), paste("p", ., sep=""))) #add tag brand to each tag id 
      




#make combined receiver/ sender column "RX_TX", and a directionless dyad column "dyad"
Tag_Data <- Tag_Data %>%
      mutate( RX_TX = paste(RX_Node, TX_Node, sep = "_")) %>% #receiver/ sender
      mutate(Dyad = ifelse(RX_Node < TX_Node, RX_TX, paste(TX_Node, RX_Node, sep = "_"))) %>% # directionless dyad
      mutate(TX_RX_Positions = paste(RX_Position, TX_Position, sep = "_")) %>%
      mutate(Dyad_Positions = ifelse(RX_Position < TX_Position, TX_RX_Positions, paste(TX_Position, RX_Position, sep = "_"))) #directionless positions


#same for test table
test_table <- test_table %>%
      mutate( RX_TX = paste(RX_Node, TX_Node, sep = "_")) %>%
      mutate(TX_RX_Positions = paste(RX_Position, TX_Position, sep = "_")) %>%
      mutate(TX_RX_Positions = ifelse(TX_RX_Positions == "NA_NA", NA, TX_RX_Positions)) %>%
      mutate(Dyad = ifelse(RX_Node < TX_Node, RX_TX, paste(TX_Node, RX_Node, sep = "_"))  ) 
      


#make separate dummy columns columns for test distance and tag orientation
test_table <- test_table %>%
      mutate( test_type = paste(test, type_parallel, sep = "_"))

#show trial durations in test_table
test_table <- test_table %>%
      mutate(trial_duration = difftime(end_time,start_time, units = "secs"))%>%
      mutate(trial_duration = as.numeric(trial_duration))


# Add trial types to Tag_Data by time range

# Show each of the time values 
test_table %>%
      select(tag, test_type, start_time, end_time) %>%
      group_by(tag, test_type)%>%
      filter(row_number()==1) %>% filter(tag== "proxlog")

# add the trial type to each data read (row) taken during that trial
Tag_Data <- Tag_Data %>%
      mutate(test_type = case_when(
Date_Time >= as.POSIXct("2024-01-25 23:55:00", tz = "America/New_York") & Date_Time <=   as.POSIXct("2024-01-26 00:00:00", tz = "America/New_York") ~ "1mgrid_5p_2s_750d_parallel",

Date_Time >= as.POSIXct("2024-01-26 00:01:00", tz = "America/New_York") & Date_Time <= as.POSIXct("2024-01-26 00:06:00", tz = "America/New_York") ~ "1mgrid_5p_2s_15d_parallel",

Date_Time >= as.POSIXct("2024-01-26 00:08:00", tz = "America/New_York") & Date_Time <= as.POSIXct("2024-01-26 00:13:00", tz = "America/New_York") ~ "1mgrid_5p_10s_750d_parallel",

Date_Time >= as.POSIXct("2024-01-26 00:15:00", tz = "America/New_York") & Date_Time <= as.POSIXct("2024-01-26 00:20:00", tz = "America/New_York") ~ "1mgrid_5p_20s_750d_parallel",

Date_Time >= as.POSIXct("2024-01-26 00:28:00", tz = "America/New_York") & Date_Time <= as.POSIXct("2024-01-26 23:00:00", tz = "America/New_York") ~ "1mgrid_5p_20s_750d_2_parallel", 

Date_Time >= as.POSIXct("2024-01-27 00:13:00", tz = "America/New_York") & Date_Time <=  as.POSIXct("2024-01-27 00:18:00", tz = "America/New_York") ~ "20cmcircle_10p_5s_750d_1_NA", 

Date_Time >= as.POSIXct("2024-01-27 00:20:00", tz = "America/New_York") & Date_Time <= as.POSIXct("2024-01-27 00:25:00", tz = "America/New_York") ~ "20cmcircle_5p_5s_750d_1_NA",

Date_Time >= as.POSIXct("2024-01-27 00:26:00", tz = "America/New_York") & Date_Time <= as.POSIXct("2024-01-27 00:31:00", tz = "America/New_York") ~ "20cmcircle_10p_5s_750d_2_NA",

Date_Time >= as.POSIXct("2024-01-27 00:33:00", tz = "America/New_York") & Date_Time <= as.POSIXct("2024-01-27 00:38:00", tz = "America/New_York") ~ "20cmcircle_5p_5s_750d_2_NA",

.default = "group_no"
))

# From here on out, the data should only include contacts recorded during tests
#only include the meetings from known tests
Tag_Data <- Tag_Data %>%
      filter(test_type!= "group_no")

## remove cardinal directions from directionless trials (the circle trials) 
#case when test_type includes "circle", RX_Position, TX_position, TX_RX_positions, Dyad_Positions are all NA

Tag_Data <- Tag_Data %>%
mutate_at(vars("RX_Position","TX_Position", "TX_RX_Positions", "Dyad_Positions"),
          ~ case_when(grepl("circle", test_type ) ~ paste(NA), # add position to all tags
                       TRUE ~ . #keep any original values that were not changed
                         )
)
             

```

```{r}

# join reference test-table with known distances and Tag_Data 

# make dummy variables for joining test_table and Tag_Data (combine dyads by test)
test_table <- test_table %>%
      mutate( Dyad_test_type = paste(Dyad, test_type, sep = "_"))

Tag_Data <- Tag_Data %>%
      mutate( Dyad_test_type = paste(Dyad, test_type, sep = "_"))

#add the test_table values to the data
# Tag_Data$distance_cm <- test_table$distance_cm[match(Tag_Data$Dyad_test_type, test_table$Dyad_test_type)]

#use inner-join to drop all group_nos
#join by Dyad_test_type 
#would like to keep distance_cm, download_rate, sample_rate, N_tags


Tag_Data <- test_table %>%
      select(Dyad_test_type, distance_cm, download_rate, sample_rate, N_tags, trial_duration) %>%
      right_join(Tag_Data, by = "Dyad_test_type")

#separate test_type, copy column not necessary
Tag_Data <- Tag_Data %>%
      mutate(test_type1 = test_type)  %>%
     separate(test_type1, c("test", NA))


#also, make tags ordered factors 
Tag_Data <- Tag_Data %>% 
      mutate_at(vars(RX_Node, TX_Node, Dyad), ~  factor(., ordered = TRUE)) 

#make date time posixct
Tag_Data$Date_Time <-  as.POSIXct(Tag_Data$Date_Time, tz= "ETC")


#remove duplicate rows
Tag_Data <-Tag_Data %>%
  distinct(.keep_all = TRUE)

```


## Data analysis

When did the tags record contacts (meetings between tags?) (Should be between ~23:50 Jan 25 and 23:00 Jan 26, between 00:00-00:40 Jan 27  
```{r, echo = FALSE}

 
 class(Tag_Data$Date_Time)
#cut out times from before the loggers updated the default time
Tag_Data <- Tag_Data %>% 
     filter(Date_Time > as.POSIXct('2023-11-10 00:00:01', tz= "ETC")) 

#meetings received
Tag_Data %>% 
      ggplot( aes(y=RX_Node, x= as.POSIXct(Date_Time), color= tag)) +
      geom_point()

### Meetings transmitted by time
Tag_Data %>% 
      ggplot( aes(y=TX_Node, x= as.POSIXct(Date_Time), color= tag)) +
      geom_point() 
```
All tags recorded meetings on the expected time ranges


```{r, echo = FALSE}

#show the new max and min times for each tag
# Tag_Data %>% 
#       group_by(RX_Node) %>%
#       summarize(n=n(), max = max(Date_Time), min= min(Date_Time))

```


```{r}
#rename trial names  intuitively

unique(Tag_Data$test_type)
Tag_Data <- Tag_Data %>%
      #mutate(trial = test_type) %>%
      mutate(trial = case_match(test_type,
                               "1mgrid_5p_2s_750d_parallel"~  "baseline" , 
                                "1mgrid_5p_2s_15d_parallel" ~ "frequent_download" , 
                               "1mgrid_5p_10s_750d_parallel" ~  "lower_sampling_10",
                                "1mgrid_5p_20s_750d_parallel" ~ "lower_sampling_20",
                                "1mgrid_5p_20s_750d_2_parallel" ~"battery_life" , 
                               "20cmcircle_10p_5s_750d_1_NA" ~ "tag_number_10_1",
                               "20cmcircle_10p_5s_750d_2_NA" ~ "tag_number_10_2",
                               "20cmcircle_5p_5s_750d_2_NA" ~ "tag_number_5_2",
                               "20cmcircle_5p_5s_750d_1_NA" ~ "tag_number_5_1"
                                 )
             )


```


###  Does downloading more often cause more data loss? How is data loss when we only download after 750 meetings? 

Does downloading more often cause more data loss? (downloading to base station every time 15 reads are logged, vs every time 750 reads are logged) 

       Compare baseline and high download rate to see if high download rate results in higher rates of data loss
- % lost in 5 minutes  (over whole test) ( per tag, per dyad)
- % lost every minute? 



```{r}
#PUll data where only difference is download frequency (tried to download to base station every time a tag logs 750 meetings, or every time tag logs 15 meetings)
# 5 minute long trial

#variables = download_test (actually, pull out, above), groups compared


download_test <- Tag_Data %>%
      filter(trial =="baseline" |trial == "frequent_download")


#accuracy by dyad
 accuracy_by_download_dyad <- 
      Tag_Data %>% 
      group_by(trial, Dyad) %>% #Dyad
      summarize(n=n(), trial_duration = max(trial_duration), sample_rate = max(sample_rate), N_tags= max(N_tags) ) %>%
      mutate(expected = (trial_duration/sample_rate*2)) %>% #(*2 bc each dyad should have detected eachother)
      mutate(pct_detected = n/expected*100, pct_missing = 100-(n/expected*100))
 accuracy_by_download_dyad

sum_download_accuracy_dyad <-
      accuracy_by_download_dyad %>%
      group_by(trial) %>%
      summarize(mean_pct_detected = mean(pct_detected), sd= sd(pct_detected), mean_pct_missing = mean(pct_missing))
sum_download_accuracy_dyad

      ggplot(data = accuracy_by_download_dyad, aes( x = trial, y = pct_detected, color = Dyad )) +
      geom_point() +
      geom_point(data = sum_download_accuracy_dyad, aes(x=trial, y=mean_pct_detected), color = "red" )+
      ylab("% of meetings detected") +
      xlab("Trial")     

      
#accuracy score by transmitting tag
accuracy_by_download_tag <- 
      Tag_Data %>% 
      group_by(trial, TX_Node) %>% #Dyad or TX_Node
      summarize(n=n(), trial_duration = max(trial_duration), sample_rate = max(sample_rate), N_tags= max(N_tags) ) %>%
      mutate(expected = (trial_duration/sample_rate*(N_tags-1))) %>%
      mutate(pct_detected = n/expected*100, pct_missing = 100-(n/expected*100))
 accuracy_by_download_tag

sum_download_accuracy_tag <-
      accuracy_by_download_tag %>%
      group_by(trial) %>%
      summarize(mean_pct_detected = mean(pct_detected), sd= sd(pct_detected), mean_pct_missing = mean(pct_missing))
sum_download_accuracy_tag

      ggplot(data = accuracy_by_download_tag, aes( x = trial, y = pct_detected, color = TX_Node )) +
      geom_point() +
      geom_point(data = sum_download_accuracy_tag, aes(x=trial, y=mean_pct_detected), color = "red" )+
      ylab("% of meetings transmitted") +
      xlab("Trial")
 

#are some dyads overall detected less? 
#overall Dyad accuracy in the different tests
  Dyad_accuracy <-  accuracy_by_download_dyad %>%
            group_by(Dyad) %>%
            summarize(mean_pct_detected = mean(pct_detected), sd= sd(pct_detected), mean_pct_missing = mean(pct_missing)) %>%
            
      ggplot( aes(x=Dyad, y=mean_pct_detected)) + 
  geom_errorbar(aes(ymin=mean_pct_detected-sd, ymax=mean_pct_detected+sd), width=.3) +
  geom_point(size=2)
    Dyad_accuracy 

    Tag_accuracy <-  accuracy_by_download_tag %>%
            group_by(TX_Node) %>%
            summarize(mean_pct_detected = mean(pct_detected), sd= sd(pct_detected), mean_pct_missing = mean(pct_missing)) %>%
            
      ggplot( aes(x=TX_Node, y=mean_pct_detected)) + 
  geom_errorbar(aes(ymin=mean_pct_detected-sd, ymax=mean_pct_detected+sd), width=.3) +
  geom_point(size=2)
    Tag_accuracy 

#could do a model looking at the effect of tag on accuracy 
```
#make fn 
```{r}
#PUll data where only difference is download frequency (tried to download to base station every time a tag logs 750 meetings, or every time tag logs 15 meetings)
# 5 minute long trial

#variables = download_test (actually, pull out, above), groups compared


comparison <- Tag_Data %>%
      filter(trial =="baseline" |trial == "frequent_download")

accuracy_test <- function(comparison = comparison, Title = "Data loss by treatment" ){
      
#accuracy by dyad
 accuracy_by_dyad <- 
      comparison %>% 
      group_by(trial, Dyad) %>% #Dyad
      summarize(n=n(), trial_duration = max(trial_duration), sample_rate = max(sample_rate), N_tags= max(N_tags) ) %>%
      mutate(expected = (trial_duration/sample_rate*2)) %>% #(*2 bc each dyad should have detected eachother)
      mutate(pct_detected = n/expected*100, pct_missing = 100-(n/expected*100))
 accuracy_by_dyad

sum_accuracy_dyad <-
      accuracy_by_dyad %>%
      group_by(trial) %>%
      summarize(mean_pct_detected = mean(pct_detected), sd= sd(pct_detected), mean_pct_missing = mean(pct_missing))
sum_accuracy_dyad

   dyad_accuracy_plot <-
         ggplot(data = accuracy_by_dyad, aes( x = trial, y = pct_detected, color = Dyad )) +
      geom_point() +
      geom_point(data = sum_accuracy_dyad, aes(x=trial, y=mean_pct_detected), shape = 3, color = "red" )+
      theme(axis.text.x = element_text(angle = 45))  +
      ylim(0,100) +
      ylab("% of Dyad meetings detected") +
      xlab("Trial") +
      ggtitle(paste(Title, "by dyad"))

      
#accuracy score by transmitting tag
accuracy_by_tag <- 
      comparison %>% 
      group_by(trial, TX_Node) %>% #Dyad or TX_Node
      summarize(n=n(), trial_duration = max(trial_duration), sample_rate = max(sample_rate), N_tags= max(N_tags) ) %>%
      mutate(expected = (trial_duration/sample_rate*(N_tags-1))) %>%
      mutate(pct_detected = n/expected*100, pct_missing = 100-(n/expected*100))
 accuracy_by_tag

sum_accuracy_tag <-
      accuracy_by_tag %>%
      group_by(trial) %>%
      summarize(mean_pct_detected = mean(pct_detected), sd= sd(pct_detected), mean_pct_missing = mean(pct_missing))
sum_accuracy_tag

      tag_accuracy_plot <-
            ggplot(data = accuracy_by_tag, aes( x = trial, y = pct_detected, color = TX_Node )) +
      geom_point() +
      geom_point(data = sum_accuracy_tag, aes(x=trial, y=mean_pct_detected), shape = 3, color = "red" )+
       ylim(0,100) +
      ylab("% of meetings detected") +
       theme(axis.text.x = element_text(angle = 45))  +
      xlab("Trial") +
      ggtitle(paste(Title, "by tag"))
 
p <-       list(accuracy_by_dyad, sum_accuracy_dyad, dyad_accuracy_plot, sum_accuracy_tag, tag_accuracy_plot)
p
}
```



Accuracy in baseline conditions

```{r}
baseline_accuracy <-  Tag_Data %>%
      filter(trial =="baseline") %>%
accuracy_test(., Title = "baseline accuracy")

baseline_accuracy[[3]]
#ggsave("Proxlog_baseline_accuracy_dyad.jpg")

baseline_accuracy[[5]]
#ggsave("Proxlog_baseline_accuracy_tag.jpg")

baseline_accuracy
```
Predictability of # of dyadic meetings detected over course of 1 5 minute trial. 


```{r}
 Tag_Data %>%
      filter(trial =="baseline")%>%
      head()



 #baseline trial ran for 300 seconds
#had 2 second sample rate
#expected dyad = duration /sample rate *2 (two tags sending and receiving)
#expected transmitted per tag (TX_node)= duration s /sample rate *(n-1)
#cut into bins of about 20 seconds (~15 breaks). Expected # of reads/dyad should be 20: 
#expected reads per tag would be that *5 reads 
#expected = 360


# possible groups: Dyad, TX_Node, RX_Node

time_fn <- function(data = data, Trial= Trial, Trial_type = "baseline", group = group, breaks = 15, expected = 20) {
   
 


            data %>%
            filter({{Trial}} == Trial_type) %>%
            arrange(Date_Time) %>% 
            mutate( time_ints = cut(Date_Time, breaks = breaks)) %>%
             group_by(time_ints, {{group}}) %>% 
            summarise(n=n()) %>%
            ggplot(aes(x=time_ints, y= n, group = {{group}}, color = {{group}})) +
            geom_point() +
            geom_line()+
            geom_hline(yintercept= expected, linetype="dashed", #add "expected
                color = "red") +
            theme(axis.text.x = element_text(angle = 45))  +
            ylab("n meetings recorded") +
            xlab("time step") +
            ggtitle("Do different nodes consistently record different amounts of contacts?")
      
      
}


   
time_fn(data= Tag_Data, Trial = trial, Trial_type ="baseline", group= Dyad)
#ggsave("differences in meetings between dyads.jpg")

time_fn(data= Tag_Data, Trial = trial, Trial_type ="baseline", group= TX_Node, expected = 40)
time_fn(data= Tag_Data, Trial = trial, Trial_type ="baseline", group= RX_Node, expected = 40)
#ggsave("proxlog_differences in recorded by receiving tags.jpg")

time_fn(data= Tag_Data, Trial = trial, Trial_type ="baseline", group= TX_Node, expected = 120, breaks = "mins")
#ggsave("proxlog_differences in meetings between tags_min.jpg")

time_fn(data= Tag_Data, Trial = trial, Trial_type ="baseline", group= Dyad, expected = 60, breaks = "mins")
#ggsave("proxlog_differences in meetings between Dyads_min.jpg")

  


```



```{r}
#comparing download rate
download_rate_comparison <- Tag_Data %>%
      filter(trial =="baseline" |trial == "frequent_download") %>%
accuracy_test(., Title = "Download Rate Comparison")

download_rate_comparison[[3]]
ggsave("Proxlog_Effect of download rate on data loss_dyad.jpg")
```
```{r}

```



```{r}
#comparing sampling rate
 sample_rate_comparison <- Tag_Data %>%
      filter(trial =="baseline" |trial == "lower_sampling_10" |trial == "lower_sampling_20") %>%
      mutate(trial = case_match(trial,
                 "baseline" ~ "2 s",
                 "lower_sampling_10" ~ "10 s",
                 "lower_sampling_20" ~ "20 s")) %>%
      mutate(trial = fct_reorder(trial, sample_rate)) %>%
      
accuracy_test(., Title = "Effect of sampling rate on data loss")
 sample_rate_comparison[[2]]
ggsave("Proxlog_Effect of sampling rate on data loss.jpg")
sample_rate_comparison



#comparison tag number 
tag_number_comparison <- Tag_Data %>%
      filter(trial =="tag_number_10_1" |trial == "tag_number_10_2" |trial == "tag_number_5_1" | trial == "tag_number_5_2") %>%
       mutate(trial = case_match(trial,
                 "tag_number_10_1" ~ "10 tags test 1",
                 "tag_number_10_2" ~ "10 tags test 2",
                 "tag_number_5_1" ~ "5 tags test 1",
                 "tag_number_5_2" ~ "5 tags test 2")) %>%
accuracy_test(., Title = "Effect of tag number on data loss") #other tags were hibernating
 

tag_number_comparison[[3]]
ggsave("Proxlog_Effect of tag number on data loss_dyad.jpg")
tag_number_comparison[[5]]
ggsave("Proxlog_Effect of tag number on data loss_tag.jpg")

tag_number_comparison

#ggsave("Proxlog_Effect of tag number on data loss.jpg")


      #frequent downloads result in more data-loss. 
      # Some Dyads are consistently undersampled. 
      
#make accuracy score for dyads
      #fix accuracy scores for circle tests
#make dyad and tag level accuracy scores for each comparison that is interesting
#can later compare pct_detected across trials to see if particular RX or TX are consistently bad


```
##overall  of performance accross different Jan 26 tests
```{r}
 overall_comparison <- Tag_Data %>%
      filter(trial != "tag_number_10_1" & #pull out less comparable tests
                   trial != "tag_number_10_2" &
                   trial != "tag_number_5_1" &
                   trial != "tag_number_5_2") %>%
      accuracy_test(., Title = "Comparison of tag performance between tests")
 overall_comparison

overall_comparison[[3]]
#ggsave("overall comparison of performance in jan proxlog tests dyad.jpg")

```
Is Dyad a significant variable in predicting pct_detected?
```{r}
library(lme4)
#dulog_summary[[1]] 
# % detected 

#simple anova seems to think dyad is a significant variable 
summary(aov(pct_detected ~ Dyad, data = overall_comparison[[1]]))


```


## troubleshooting circle test, unclear (maybe data downloaded multiple times? Make code for getting rid of duplicates)
## what is the transmission rate? 
```{r}
#what times did each tag transmit
Tag_Data %>%
      filter(trial =="tag_number_10_1" |trial == "tag_number_10_2" |trial == "tag_number_5_1" | trial == "tag_number_5_2") %>%
    #  filter(trial== "tag_number_10_1") %>%
      ggplot(aes(x=Date_Time, y=TX_Node, color = trial)) +
      #geom_jitter() +
      geom_point()


# were tags transmitting every second? #looks like there is some duplicate data

Tag_Data %>% 
     filter(Date_Time > as.POSIXct('2024-01-27 00:30:00', tz= "ETC")) %>%
      filter(Date_Time < as.POSIXct('2024-01-27 00:31:00', tz= "ETC")) %>%
     #filter(RX_Node == "p2") %>%
      filter(RX_TX == "p2_p3") %>%
      ggplot(aes(x=Date_Time, y=trial)) +
       geom_jitter(width=0, height=0.02) 

      #geom_point()
#RX_TX and time == duplicate
#there were duplicates, they are gone now 

```
## performance over time

This test was designed to see if performance would drop over time as battery levels decreased. 
The Y is number of contacts logged over 30 minutes for each tag. X is time. If performance declined with battery levels, then you would expect a downward slope, especially at the end. 
```{r}

  #trial ran for 81120 seconds. cut into bins of about 30 minutes: 
81120/(30*60)
#expected = 180
#Dyad: 60*30/20 
300
Tag_Data %>%
      filter(trial == "battery_life") %>%
      arrange(Date_Time) %>% 
      mutate( time_ints = cut(Date_Time, breaks = 36)) %>%
       group_by(time_ints, Dyad) %>% 
      summarise(n=n()) %>%
      ggplot(aes(x=time_ints, y= n, color = Dyad)) +
      geom_point() +
      geom_hline(yintercept= 180, linetype="dashed", # expected
                color = "red") +
      theme(axis.text.x = element_text(angle = 45)) +
      ylim(0, 200)
      
#ggsave("battery_life_proxlog.jpg")
(60*30)/20*(5-1)     

 # dskjdhfkseh
 # would he pay for it himself. ##let him know let him know asap. 
 # he could down 
 # email sauer glue 
 #  estimate Caleb arrival (3 weeks) 
 # first impressions!
# do his comparison with dulog, email simon, email Nikklas



```

There are some steep dips over the day. One possible explanation is that some of the tags fell to the floor overnight, and I stuck them back on when I came to clean the next morning. This could be those tags. It would show that transmission goes down with proximity to the floor (a  known issue) 








The two tags have similar ranges. But the dulogs detected tags up to at least 4m from center
Dulog reads more evenly than proxlog


### Signal Strength (RSSI) by Distance
```{r, echo = FALSE}
Tag_Data$RSSI <- as.numeric(Tag_Data$RSSI)


#signal strength by distance in flight cage
Tag_Data %>%
      filter(trial != "battery_life" ) %>%
      filter(!grepl("circle",test_type)) %>%
ggplot(aes(y=RSSI, x= distance_cm, color = Dyad)) +
      geom_point(position = "jitter", alpha =.5) +
      facet_wrap(~test_type, drop = TRUE)

ggsave("RSSI_by_distance_proxlog_flightcage.jpg")
## very much not reliable by distance in this context-- way too much interference? 



# # trying to summarize distance
Tag_Data %>%
      group_by(tag, distance_cm) %>%
      filter(distance_cm != "NA") %>%
      mutate(dist_test = paste(distance_cm, test_type, sep = "_")) %>%
ggplot(aes(y=RSSI, x= as.factor(distance_cm))) +
      geom_violin()
 
#completely unreliable across these distances

str(Tag_Data)
```


#write combined dataset
```{r}

Tag_Data <-Tag_Data %>%
  distinct(.keep_all = TRUE)

Tag_Data_Jan26 <-
      Tag_Data %>%
      select(!Dyad_test_type) %>% #drop dyad dummy variable 
      relocate(Dyad, RSSI, Date_Time, trial, test_type)
#write.csv(Tag_Data, "Jan26_logger_testing.csv")

```


##############


