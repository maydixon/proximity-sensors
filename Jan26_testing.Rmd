---
title: "Proxlog testing Jan 26 "
output:
  pdf_document: default
  html_notebook: default
---
	tag positions
	5N (towards recording booths)
	3W (towards exit)
	4E (towards cages)
	2S (towards monitor)
	1C
	
	5 minutes each
	 
	((baseline))
	11:55:00-12:00:00  
	5 tags
	1 meter grid
	2 second sampling
	download at 750 reads
	
	((previous high downloading rate, possibly higher than before)
	12:01:00 - 12:06:00
	5 tags
	1 meter grid
	2 second sampling 
	download at 15 reads ( was maybe 2 during last tests)
	((changed over at ~12:00, waited to start bc maybe a backload of downloading)) 
	
	
	((lower sampling rate))
	12:08:00 - 12:13:00
	5 tags
	1 meter grid
	10 second sampling
	download at 750 reads
	
	((even lower sampling rate))
	12:15-12:20
	5 tags
	1 meter grid
	20 second sampling
	download at 750 reads
	
	(connected blutooth hotspot at mid 12:18-12:19, in case that had an effect) 
	-----
	((battery life)) 
	12:28
	5 tags, run all night 
	5 tags
	1 meter grid
	20 second sampling
	download at 750 reads
	
	@12:28: 
	1=83%
	2=92%
	3=92%
	4=91%
	5=78%
	
27/01/24
Tag number test (test 10 vs 5 tags to see if there is more data loss with 10 )
	00:13- 00:18
	10 tags
	In circle 
	5 second sampling 
	Download at 750 reads 
	
	00:20- 00:25
	5 tags 2,4,6,9,11  (alternate tags hidden: not scanning) 
	5 sec scanning
	Download at 750 reads 
	
	00:26- 00:31
	10 tags
	In circle 
	5 second sampling 
	Download at 750 reads
	
	0:33-0:38
	(Other 5 tags) 
	5 tags 1,3,5,7,10 (alternate tags hidden: not scanning) 
	5 sec scanning
	Download at 750 reads

	
	_____
	
	# of tags A- low
	5 tags
	in circle
	10 second sampling
	download at 750 reads
	
	# of tags B- high
	10 tags
	in circle
	10 second sampling
	download at 750 read

#make test table with all dyads
#OR A TEST TABLE with just all tests
# add test info
# combine with tag- data
```{r setup, echo= FALSE}
# set up 
```


```{r, include = FALSE}
library(tidyverse)
library(readr)
library(lubridate)
```

--> Data wrangling: import data
```{r import data, include = FALSE}

# test_table defines the times when each test was conducted

# Use this code if pulling test_table from github (double check github sometimes pulls csvs in weird) 
 test_table <- read_csv("https://raw.githubusercontent.com/maydixon/proximity-sensors/real/test_table_Jan26.csv") 


# import proxlog data- take all the files in a folder and pull them into the same dataframe
# (for some obnoxious reason, L3 and L4 read in with col names automatically with read_CSV, and the others don't, so I used read.csv)
PR_DATA <- list.files(path = "proxlog_Jan26_test/",  # Identify all CSV files with L in the name
                       pattern = "L", full.names = TRUE) %>% #
  lapply(read.csv, col.names = c("RX_Node","TX_Node","Date_Time", "RSSI")) %>%                              # Store all files in list
  bind_rows         %>%                     # Combine data sets into one data set 
  mutate(tag = "proxlog") #add proxlog to all rows


### extra data from last test
PR_DATA_2 <- list.files(path = "Proxlogs_numtest/",  # Identify all CSV files with L in the name
                       pattern = "L", full.names = TRUE) %>% #
  lapply(read.csv, col.names = c("RX_Node","TX_Node","Date_Time", "RSSI")) %>%                              # Store all files in list
  bind_rows         %>%                     # Combine data sets into one data set 
  mutate(tag = "proxlog") #add proxlog to all rows

PR_DATA <- bind_rows(PR_DATA, PR_DATA_2)
## Tags 7, 10 and 11 originally have very much the wrong (default) times, but they do update before the tests. 

```

--> Data wrangling: fix and standardize Dulog and data_table, and proxlog date/times
```{r, include = FALSE}

# put date time in one column for reference table
test_table <- test_table %>%
      mutate(start_time = make_datetime(year = start_year, month = start_month, day = start_day, hour = start_hour, min =  start_minute, sec = start_second), 
             end_time = make_datetime(year = end_year, month = end_month, day = end_day, hour = end_hour, min =  end_minute, sec = end_second))


#Make test_table for the test of whether more tags causes more data loss (all tags in 20cm circle, either 5 or 10 tags activated)
#entering the text_table directly here, to take advantage of complete() for making all possible dyads


#X = length of initial dataset, will all column values, pre using complete to make all possible combinations
X=10 #length of longest variable (tag_A and B here)
ntags_test_table <- tibble(
  tag = c(rep("proxlog", length.out = X)),
  test = c(rep(c("20cmcircle_10p_10s_750d_1","20cmcircle_5p_10s_750d_1", "20cmcircle_10p_5s_750d_2", "20cmcircle_5p_10s_750d_2"), length.out = X)),
    tag_A = c(1:7,9:11), 
  tag_B = c(1:7,9:11),
  start_time = as.POSIXct(c(rep(c("2024-01-27 00:13:00", "2024-01-27 00:20:00", "2024-01-27 00:26:00", "2024-01-27 00:33:00"), length.out = X))),
  end_time = as.POSIXct(c(rep(c("2024-01-27 00:18:00", "2024-01-27 00:25:00", "2024-01-27 00:31:00", "2024-01-27 00:38:00"), length.out = X))),
  N_tags = c(rep(c(10,5,10,5), length.out = X)),
  sample_rate = c(rep(10, length.out=X)),
  download_rate = c(rep(750, length.out=X))
) %>%
      complete(test, tag_A, tag_B) %>% #make all possible dyad combinations
      arrange(test,start_time) %>% #make it so filled values for each test come first to fill in missing values
      fill(c(tag, start_time, end_time, N_tags, sample_rate, download_rate), .direction = "down")  #fill in NAs
ntags_test_table 
      
#bind to test table 
test_table <- bind_rows(test_table, ntags_test_table)
```

```{r}
#Force into same timezone
test_table$start_time <-  force_tz(test_table$start_time, tzone = "America/New_York")


# correct data and time for PR_DATA

# PR_DATA, convert character to POSIX (OG timezone is a default GMT )
PR_DATA$Date_Time <-  as.POSIXlt(PR_DATA$Date_Time, format ="%d/%m/%Y %H:%M:%S", tz= "Etc/GMT" )

#change to real time zone, same format as other dataset
PR_DATA$Date_Time<- with_tz(PR_DATA$Date_Time, tzone = "America/New_York")
head(PR_DATA$Date_Time)
head(PR_DATA)



Tag_Data <- PR_DATA


# Make tag names indicate tag type (d or p), then position (SNEWC), then unique ID e.g. "69"
#if rerunning run from top
test_table <- test_table %>%
      mutate(RX_Node = paste(TagA_position, tag_A,  sep = ""), 
             TX_Node = paste(Tag_B_position, tag_B, sep = "")) %>%
      mutate_at( c("RX_Node", "TX_Node"), funs(ifelse(tag=="dulog", paste("d", ., sep=""), paste("p", ., sep=""))))


# add cardinal position (N, S E W, C) to each tag type and tag brand
Tag_Data <- Tag_Data %>%
      mutate_at(vars("RX_Node","TX_Node"), ~ as.character(.)) %>%
     mutate_at(vars("RX_Node","TX_Node"), ~ case_when( . == "1" ~ paste("C", ., sep = ""), # add position to all tags
                                                       . == "2" ~ paste("S", ., sep = ""),
                                                       . == "3" ~ paste("W", ., sep = ""),
                                                       . == "4" ~ paste("E", ., sep = ""),
                                                       . == "5" ~ paste("N", ., sep = ""),
                                                      TRUE ~ . #keep any original values that were not changed
                                                      )
              ) %>%
       mutate_at( vars("RX_Node", "TX_Node"), ~ ifelse(tag=="dulog", paste("d", ., sep=""), paste("p", ., sep=""))) #add tag brand to each tag id 
      

#make combined receiver/ sender column "RX_TX", and a directionless dyad column "dyad"
Tag_Data <- Tag_Data %>%
      mutate( RX_TX = paste(RX_Node, TX_Node, sep = "_")) %>% #receiver/ sender
      mutate(Dyad = ifelse(RX_Node < TX_Node, RX_TX, paste(TX_Node, RX_Node, sep = "_"))  ) # directionless dyad
  
#same for test table
test_table <- test_table %>%
      mutate( RX_TX = paste(RX_Node, TX_Node, sep = "_")) %>%
      mutate(Dyad = ifelse(RX_Node < TX_Node, RX_TX, paste(TX_Node, RX_Node, sep = "_"))  )


#make separate dummy columns columns for test distance and tag orientation
test_table <- test_table %>%
      mutate( test_type = paste(test, type_parallel, sep = "_"))



# Add trial types to Tag_Data by time range

# Show each of the time values 
test_table %>%
      select(tag, test_type, start_time, end_time) %>%
      group_by(tag, test_type)%>%
      filter(row_number()==1) %>% filter(tag== "proxlog")

# add the trial type to each data read (row) taken during that trial
Tag_Data <- Tag_Data %>%
      mutate(test_type = case_when(
Date_Time >= as.POSIXct("2024-01-25 23:55:00", tz = "America/New_York") & Date_Time <= as.POSIXct("2024-01-26 00:00:00", tz = "America/New_York") ~ "1mgrid_5p_2s_750d_parallel",
Date_Time >= as.POSIXct("2024-01-26 00:01:00", tz = "America/New_York") & Date_Time <= as.POSIXct("2024-01-26 00:06:00", tz = "America/New_York") ~ "1mgrid_5p_2s_15d_parallel",
Date_Time >= as.POSIXct("2024-01-26 00:08:00", tz = "America/New_York") & Date_Time <= as.POSIXct("2024-01-26 00:13:00", tz = "America/New_York") ~ "1mgrid_5p_10s_750d_parallel",
Date_Time >= as.POSIXct("2024-01-26 00:15:00", tz = "America/New_York") & Date_Time <= as.POSIXct("2024-01-26 00:20:00", tz = "America/New_York") ~ "1mgrid_5p_20s_750d_parallel",
Date_Time >= as.POSIXct("2024-01-26 00:28:00", tz = "America/New_York") & Date_Time <= as.POSIXct("2024-01-26 23:00:00", tz = "America/New_York") ~ "1mgrid_5p_2s_750d_2_parallel",
.default = "group_no"
))


# join reference test-table with known distances and Tag_Data 

# make dummy variables for joining test_table and Tag_Data
test_table <- test_table %>%
      mutate( Dyad_test_type = paste(Dyad, test_type, sep = "_"))

Tag_Data <- Tag_Data %>%
      mutate( Dyad_test_type = paste(Dyad, test_type, sep = "_"))

#add the test_table values to the data
Tag_Data$distance_cm <- test_table$distance_cm[match(Tag_Data$Dyad_test_type, test_table$Dyad_test_type)]

#separate test_type, copy column 
Tag_Data <- Tag_Data %>%
      mutate(test_type1 = test_type)  %>%
     separate(test_type1, c('test', 'type_parallel'))


#also, make tags ordered factors 
Tag_Data <- Tag_Data %>% 
      mutate_at(vars(RX_Node, TX_Node), ~  factor(., ordered = TRUE)) 

```


## Data analysis

When did the tags record contacts (meetings between tags?) (Should be between ~23:50 Jan 25 and 23:00 Jan 26) 
```{r, echo = FALSE}

 
 class(Tag_Data$Date_Time)


Tag_Data %>% 
      ggplot( aes(y=RX_Node, x= as.POSIXct(Date_Time), color= tag)) +
      geom_point()



```
All 5 tags recorded meetings on the expected time ranges


### Meetings recorded by transmitting tags by time

tags should have transmitted over the same time range, and did. 
```{r, echo = FALSE}
Tag_Data %>% 
      ggplot( aes(y=TX_Node, x= as.POSIXct(Date_Time), color= tag)) +
      geom_point() 

```



```{r, echo = FALSE}

Tag_Data$Date_Time <-  as.POSIXct(Tag_Data$Date_Time, tz= "ETC")
class(Tag_Data$Date_Time)


#only include the tags from known tests
Tag_Data <- Tag_Data %>%
      filter(test_type!= "group_no")

#show the new max and min times for each tag
Tag_Data %>% summarize(n=n(), max = max(Date_Time), min= min(Date_Time))

```


Total number of reads transmitted and received by each individual tag
```{r, echo = FALSE}
#number of meetings transmitted and received by each tag
Tag_Data %>%
      group_by( TX_Node) %>%
      summarise(n=n())



#number of meetings received by each tag
Tag_Data %>%
      group_by( RX_Node) %>%
      summarise(n=n())


Tag_Data %>%
      ggplot( aes(x= RX_Node)) +
      geom_bar() + 
      facet_wrap(~tag, scales="free_x") +
      xlab("# of Contacts Received")

```
Both tags had some weird IDs, that we did not use at the time. Dulog had more. 

It is little concerning that some sensors had far more reads than others, but let's check the read number only for a time when we know all tags should have been in range (10cm), and for a standard unit of time 


```{r, echo = FALSE}
#number of meetings receieved by each tag for 10 parallel
 #transmitted at 10 parallel
Tag_Data %>%
      filter(test_type == "ten_parallel") %>%
      group_by(tag, RX_Node) %>%
      summarise(n=n())


Tag_Data %>%
      filter(test_type == "ten_parallel") %>%
      ggplot( aes(x= RX_Node)) +
      geom_bar() + 
      facet_wrap(~tag, scales="free_x")

#transmitted at 10 parallel
Tag_Data %>%
      filter(test_type == "ten_parallel") %>%
      group_by(tag, TX_Node) %>%
      summarise(n=n())

Tag_Data %>%
      filter(test_type == "ten_parallel") %>%
      ggplot( aes(x= TX_Node)) +
      geom_bar() + 
      facet_wrap(~tag, scales="free_x")

```
At known ranges, dulog had much more even receiving read rates than proxlogs, which are *really* variable
Neither of the tags did a great job at transmitting even # of meetings when the tags were all well within range (one of the dulog tags transmitted a bunch more than the others, the proxlogs are all over the map)

--> Get rid of weird values, order test_type
```{r, echo = FALSE, include = FALSE}
# only data from real tags (presumably Dyads with more than 10 readings)

Tag_Data <- Tag_Data %>%
      group_by(Dyad) %>% #get rid of weird made-up tag values
      filter(n() > 10) %>% #get rid of weird made-up tag values (fewer than 10 observations)
       mutate( test_type_tag = paste(test_type, tag, sep = "_")) %>%
      ungroup() %>% #now order test type
       mutate(test_type_tag= fct_relevel(test_type_tag,  c("ten_parallel_dulog", "ten_parallel_proxlog", "ten_moved_dulog", "ten_moved_proxlog", "fifty_parallel_dulog", "fifty_parallel_proxlog", "fifty_moved_dulog", "fifty_moved_proxlog", "hundred_parallel_dulog", "hundred_parallel_proxlog", "hundred_moved_dulog", "hundred_moved_proxlog", "twohundred_parallel_dulog", "twohundred_parallel_proxlog", "threehundred_parallel_dulog","threehundred_parallel_proxlog", "fourhundred_parallel_dulog", "fourhundred_parallel_proxlog", "fivehundred_parallel_dulog", "fivehundred_parallel_proxlog", "sixhundred_parallel_dulog"  )))
      
```


### Reads transmitted from all meetings, by trial type
```{r, echo = FALSE, fig.height = 8}
#number of meetings faceted by test_type

 Tag_Data %>%
 ggplot( aes(x= TX_Node)) +
      geom_bar() + 
      facet_wrap(~test_type, scales="free", ncol = 2)
```

### Reads transmitted from all meetings, by trial type
```{r, echo = FALSE, fig.height = 8}

 Tag_Data %>%
 ggplot( aes(x= RX_Node)) +
      geom_bar() + 
      facet_wrap(~test_type_tag, scales="free_x", ncol = 2) 
```

### Mean and variance in number of contacts per tag type
```{r, echo = FALSE}
# for each test/tag type, summarize the mean # of contacts/tagID and the variance. 
Tag_read_variance <- 
      Tag_Data %>%
       group_by(test_type_tag, RX_Node) %>%
       summarize(n=n())%>%
       pivot_wider(names_from = RX_Node, values_from = n) %>%
       rowwise() %>%
        mutate(
       mean = mean(c_across(2:9), na.rm = TRUE),
      sd = sd(c_across(2:10), na.rm = TRUE)
      ) %>%
       ungroup() %>%
       select(test_type_tag, mean, sd) %>%
       separate_wider_delim(test_type_tag, delim = "_", names = c("test", "type", "tag")) %>%
       mutate(test_type = paste(test, type,  sep = "_")) %>%
       select(-c(test, type)) %>%
       relocate(test_type)
Tag_read_variance

 Tag_read_variance %>%
       mutate(test_type = fct_relevel(test_type, c("ten_parallel", "ten_moved", "fifty_parallel", "fifty_moved", "hundred_parallel", "hundred_moved", "twohundred_parallal", "threehundred_parallel", "fourhundred_parallel"))) %>%
       ggplot(aes(x= test_type, y= sd, fill=tag)) +
       geom_bar(stat = "identity", position = "dodge") +
       theme(axis.text.x = element_text(angle = 45)) +
       ggtitle("standard deviation in # of reads between different tags in a trial")

```

The two tags have similar ranges. But the dulogs detected tags up to at least 4m from center
Dulog reads more evenly than proxlog


### Signal Strength (RSSI) by Distance
```{r, echo = FALSE}
Tag_Data$RSSI <- as.numeric(Tag_Data$RSSI)


# by tag
ggplot(data= Tag_Data, aes(y=as.numeric(RSSI), x= distance_cm, color= as.factor(tag))) +
      geom_point(position = "jitter") 

# by tag with trendline
ggplot(data= Tag_Data, aes(y=RSSI, x= distance_cm, color= as.factor(tag))) +
      #geom_point(position = "jitter") +
      geom_jitter() +
       geom_smooth( level = .99) +
      geom_smooth(method = "glm", formula = y~log(x), family = gaussian(link = 'log'))


#by RX ID
ggplot(data= Tag_Data, aes(y=RSSI, x= distance_cm, color= RX_TX)) +
      geom_jitter()


# by tag orientation
Tag_Data %>%
      group_by(distance_cm) %>%
      ggplot( aes(y=RSSI, x= distance_cm, color= type_parallel)) +
      geom_jitter() 

#by test
Tag_Data %>%
      filter(test_type != "group_no") %>%
      group_by(distance_cm) %>%
      ggplot( aes(y=RSSI, x= distance_cm, color= as.factor(test_type))) +
      geom_jitter()

# zooming in on close distances only 
# by RX ID
ggplot(data= Tag_Data, aes(y=RSSI, x= distance_cm, color= as.factor(tag))) +
      geom_jitter() +
      xlim(0, 100)


# # trying to summarize distance
Tag_Data %>%
      group_by(tag, distance_cm) %>%
      mutate(dist_test = paste(distance_cm, test_type, sep = "_")) %>%
ggplot(aes(y=RSSI, x= as.factor(distance_cm), color= tag)) +
      geom_violin()
      

str(Tag_Data)
```
Proxlog and Dulog use different signals, so they have different signal strengths at the same distances. 
Proxlog declines logarithmically, is especially steep at low distances. Dulog initially declines very precipitously and later declines  linearly. 

### Differences in signal strength variance by group
```{r, echo = FALSE}
sd_tags <- Tag_Data %>%
      filter(distance_cm < 600 ) %>%
  group_by( distance_cm, tag) %>%
      summarize(RSSI_SD=sd(RSSI), RSSI_mean = mean(RSSI), N=n())
sd_tags

sd_tags %>%
      ggplot(aes(x=distance_cm, y= RSSI_SD, color = tag )) +
      geom_point() +
      geom_smooth(level = .99) +
      xlab("Distance (cm)") +
      ylab("RSSI SD")

 

 Tag_Data %>%
       group_by(distance_cm) %>%
       filter(any(tag=="dulog") & any(tag=="proxlog")) %>% #remove groups where there aren't observations for both prox and dulogs.
       group_by(distance_cm) %>%
       group_map(~ bartlett.test(x=.$RSSI, g=.$tag))
       #bartlett.test(x=.$RSSI, g=.$tag)
 
  #bartlett.test(RSSI ~ tag)
#find the mean difference in signal strength between each group
#compare the variance between each group @ given signal strength  Bartlett test
  
  
Tag_Data %>%
      filter(distance_cm ==100.00) %>%
      group_by(test_type, tag) %>%
  filter(row_number()==1)
```

There is no obvious difference in the variation in signal strength between the two tags. 
At small distances, both tags have about the same variance, and at larger distances, dulogs seem to have higher variances in signal strength 


### Sensitivity to tag direction
```{r, echo = FALSE}
# by tag orientation
Tag_Data %>%
      group_by(distance_cm) %>%
      filter(distance_cm <= 200) %>%
      ggplot( aes(y=RSSI, x= distance_cm, color= type_parallel)) +
      geom_jitter(alpha = .8) 

#dulog comparison
Tag_orientation_p <- function(Tag) {
      Tag_Data %>%
       filter(distance_cm <= 200) %>%
      filter(tag== Tag) %>%
      group_by(distance_cm, type_parallel) %>%
      mutate(dist_pos = paste(distance_cm, type_parallel, sep = "_")) %>%
      mutate(dist_pos = fct_reorder(dist_pos, distance_cm)) %>%
      ggplot( aes(y=RSSI, x= as.factor(distance_cm), fill= type_parallel)) +
      geom_violin(alpha = .8) +
      xlab("Tag Distance") +
      ylab("Signal Strength (RSSI)") + 
      scale_fill_discrete(name = "Tag Orientation") +
      ggtitle(paste(Tag, "signal strength by tag orientation and distance", sep = " "))
      
}

Tag_orientation_p(Tag = "dulog")
Tag_orientation_p(Tag = "proxlog")



Tag_Data %>%
      filter(distance_cm <= 200) %>%
      group_by(distance_cm, tag, type_parallel) %>%
       filter(test_type == "ten_moved")
#return here
#summarize differences in orientation at each distance (not adjusted for multiple comparisons)
Tag_Data %>%
      filter(distance_cm <= 200) %>%
      group_by(distance_cm, tag) %>%
      summarize(T_test = t.test(RSSI[type_parallel=="parallel"], RSSI[type_parallel=="moved"])$p.value)


```
The orientation of the tag does not seem to have a consistent effect for either tag, though the positions in this test were not highly standard. 


##############


